	<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Tianfan Xue</title>
</head>
<body>

<!-- CSS -->
<style>
img.top {
      vertical-align: text-top;
}
img.middle {
      vertical-align: middle;
}
img.bottom {
      vertical-align: text-bottom;
}
</style>
<!-- Add something here -->
<!-- CSS -->

<div class="menu"> <a href="#bio">Bio</a> 
<a href="#members">Lab Members</a> 
<a href="#publications_recent">Recent Pub.</a> 
<a href="#education">Education</a>
<a href="#publications_others">Other Pub.</a> 
<a href="#misc">Misc.</a>
</div>

<a id="bio" class="anchor"></a>
<div id="container"><div class="container"> 
<div id="toptitle">
<h1>Tianfan Xue</h1>
</div>

<table class="imgtable"><tr><td>
<a href="./"><img src="./image/xue_tianfan.jpg" alt="" width="250px" height="250px" /></a>&nbsp;</td>
<td align="left"><p><a href="./">Tianfan Xue</a><br/>
Vice Chancellor Assistant Professor<br/>
<a href="https://www.ie.cuhk.edu.hk/">the Department of Information Engineering</a><br/>
<a href="https://www.cuhk.edu.hk/">the Chinese University of Hong Kong</a><br/>
<span style="vertical-align:middle">
	Email: </span> <img src="./image/cuhk_email.png" alt="loading..." height="20px" class="middle" height="20px"> | <img src="./image/gmail.png" alt="loading..." height="20px" class="middle"> <br/>
	For <b>IERG 4160</b> students, email: ierg4160-teaching-staff@googlegroups.com <br/>
<font color="#999999">Note: tfxue@mit.edu and tianfan@google.com are no longer active, please contact me through emails above</font> <br/>
<a href="https://scholar.google.com/citations?user=RfSQKrIAAAAJ&hl=en">Google scholar</a> |
<a href="https://www.linkedin.com/in/tianfan-xue-54016716/">Linkedin</a> |
<a href="https://orcid.org/0000-0001-5031-6618">ORCID</a>
<br/>
<br/>

<a href="https://goo.gl/maps/BYUHw3bLSd845vnZ6">Room 717 SHB</a> <br/>
The Chinese University of Hong Kong, <br/>
Shatin, N.T. <br/>
Hong Kong <br /></p>
</td></tr></table>

<h2>Biography</h2>

<p>
Tianfan Xue started as an Vice Chancellor assistant professor at the Department of Information Engineering, the Chinese University of Hong Kong in
Novermber of 2022. If you are excited about computational photography, computer vision, computer graphics, and machine learning, please contact
for potential full-funded Ph.D., master, postdoc, R.A., and intern positions available.
</p>

Tianfan Xue was working in Google Research from 2017 to 2022. Before that, Tianfan Xue received his Ph.D. from <a href="">MIT Computer Science and Artificial Intelligence Laboratory</a>, under the supervision of <a href="http://people.csail.mit.edu/billf/">William T. Freeman</a>, with thesis committee members <a href="http://people.csail.mit.edu/fredo/">Prof. Fr&eacute;do Durand</a>, <a href="https://szeliski.org/">Dr. Richard Szeliski</a>, and <a href="https://people.csail.mit.edu/celiu/">Dr. Ce Liu</a>. Also, Tianfan Xue received his Master of Philosophy in the <a href="http://www.ie.cuhk.edu.hk/">Information Engineering Department</a>, <a href="http://www.cuhk.edu.hk/english/index.html">The Chinese University of Hong Kong</a> in 2011, under the supervised of <a href="http://www.ie.cuhk.edu.hk/people/xotang.html">Prof. Xiaoou Tang</a> and <a href="http://www.ie.cuhk.edu.hk/people/jzliu.html">Prof. Jianzhuang Liu</a>. Tianfan Xue also received the B.E. degree in the <a href="http://www.tsinghua.edu.cn/publish/csen/index.html">Computer Science and Technology Department</a> from <a href="http://www.tsinghua.edu.cn/publish/then/index.html">Tsinghua University</a>, China, in 2009. Here is Tianfan Xue's Curriculum Vitae [<a href="./files/cv_tianfan.pdf">PDF</a>]. <br /></p>

<!--
   See my research statement for more details: [<a href="https://people.csail.mit.edu/tfxue/research_statement_tianfan.pdf">PDF</a>].
-->

<h2>Research Highlights</h2>
<!--
<ul>
<li>New papers in <a href="https://nips.cc/">NIPS 2016</a>:
<ul>
  <li>&ldquo;Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks&rdquo;. Oral. [<a href="http://visualdynamics.csail.mit.edu/">Website</a>] [<a href="https://github.com/tfxue/visual-dynamics">Code(Github)</a>]</li>
<li>&ldquo;Learning a Probabilistic Latent Space of ObjectShapes via 3D Generative-Adversarial Modeling&rdquo;. Poster. [<a href = "http://3dgan.csail.mit.edu/">Website</a>] [<a href="https://github.com/zck119/3dgan-release">Code(Github)</a>]</li>
</ul>
<li>New paper in <a href="http://www.eccv2016.org/">ECCV 2016</a>: &ldquo;Single Image 3D Interpreter Network&rdquo;. Oral. [<a href = "http://3dinterpreter.csail.mit.edu/">Website</a>] [<a href="https://github.com/jiajunwu/3dinn/">Code(Github)</a>]
<li>New paper in <a href="http://s2015.siggraph.org/">SIGGRAPH 2015</a>: &ldquo;A Computational Approach for Obstruction-Free Photography&rdquo;. Oral. [<a href="https://sites.google.com/site/obstructionfreephotography/">Website</a>]</li>
</ul>
-->
<!--
<iframe width="250" height="141" src="https://www.youtube.com/embed/xoyNiatRIh4" frameborder="0" allowfullscreen></iframe>
<iframe width="250" height="141" src="https://www.youtube.com/embed/mQIBdQ4WggE" frameborder="0" allowfullscreen></iframe>
<iframe width="250" height="141" src="https://www.youtube.com/embed/mfx7uAkUtCI" frameborder="0" allowfullscreen></iframe>
<iframe width="400" height="226" src="https://www.youtube.com/embed/IyPQqqGPHws?start=1728&end=2027" frameborder="0" allowfullscreen></iframe>
<iframe width="400" height="226" src="https://www.youtube.com/embed/ljrpRrRlYs8" frameborder="0" allowfullscreen></iframe>
<iframe width="400" height="226" src="https://www.youtube.com/embed/msC5GK9aV9Q" frameborder="0" allowfullscreen></iframe>
-->
<!--
<iframe width="400" height="226" src="https://www.youtube.com/embed/WmI7bv9nqjI" frameborder="0" allowfullscreen></iframe>
<iframe width="400" height="226" src="https://www.youtube.com/embed/3AHDbJlGKwY" frameborder="0" allowfullscreen></iframe>
<iframe width="400" height="226" src="https://www.youtube.com/embed/VEwYrSPFatg" frameborder="0" allowfullscreen></iframe>
<iframe width="400" height="226" src="https://www.youtube.com/embed/GP0PdaXs93E" frameborder="0" allowfullscreen></iframe>
<iframe width="400" height="226" src="https://www.youtube.com/embed/zidaYS85mCY" frameborder="0" allowfullscreen></iframe>
<iframe width="250" height="141" src="https://www.youtube.com/embed/VEwYrSPFatg" frameborder="0" allowfullscreen></iframe>
<td><iframe id="videoyt6" width="440" height="248" src="https://www.youtube.com/embed/xoyNiatRIh4" frameborder="0" allowfullscreen></iframe></td>
<td><iframe id="videoyt3" width="440" height="248" src="https://www.youtube.com/embed/yKmkXJSlAl8" frameborder="0" allowfullscreen></iframe></td>
-->
<ul>
  <li>UltraFusion, an ultra high dynamic range HDR, has won the <b>CVPR 2025 best demo honorable mention</b>.</li>
  <li>BilarfNeRF, an NeRF reconstruction with bilateral grid, has won the <b>SIGGRAPH 2024 best paper honorable mention</b>.</li>
  <li>PhocoLens, an photo-consistent diffusion, has won a <b>spotlight</b> presentation in NeurIPS 2024.</li>
</ul>
<table class="imgtable"><tbody>
<tr>
<td><iframe id="videoyt1" width="440" height="248" src="https://www.youtube.com/embed/YG7FTLDIqic" frameborder="0" allowfullscreen></iframe></td>
<td><iframe id="videoyt2" width="440" height="248" src="https://www.youtube.com/embed/bk11g3hZX5s" frameborder="0" allowfullscreen></iframe></td>
</tr>
<tr>
<td><iframe id="videoyt3" width="440" height="248" src="https://www.youtube.com/embed/hOk8TJiotag" frameborder="0" allowfullscreen></iframe></td>
<td><iframe id="videoyt4" width="440" height="248" src="https://www.youtube.com/embed/-VMV3MD1GIE" frameborder="0" allowfullscreen></iframe></td>
</tr>
<tr>
<td><iframe id="videoyt5" width="440" height="248" src="https://www.youtube.com/embed/WmI7bv9nqjI" frameborder="0" allowfullscreen></iframe></td>
<td><iframe id="videoyt6" width="440" height="248" src="https://www.youtube.com/embed/3AHDbJlGKwY" frameborder="0" allowfullscreen></iframe></td>
</tr>
</table>
<!-- <video width="480" height="260" controls><source src="http://visualdynamics.csail.mit.edu/visualDynamics.mov" type="video/mp4">Your browser does not support the video tag. Please download it from <a href="http://visualdynamics.csail.mit.edu/visualDynamics.mov">this</a>.</video> -->
</p>

<script>
function replaceVideoWithImage(videoId, imageUrl) {
  // Get the video element
  const videoElement = document.getElementById(videoId);

  if (videoElement) {
	// Create a new image element
	const imgElement = document.createElement('img');
	imgElement.src = imageUrl; // Set the image source
	imgElement.width = 400; // Match the iframe width
	imgElement.height = 228; // Match the iframe height
	imgElement.alt = 'Replacement Image'; // Add alt text for accessibility
	imgElement.style.display = 'block'; // Ensure the image is visible
	imgElement.style.borderWidth = '5px';
	imgElement.style.borderStyle = 'solid';
	imgElement.style.borderColor = 'white';

	// Replace the iframe with the image
	videoElement.parentNode.replaceChild(imgElement, videoElement);
  } else {
	console.error('Video element not found');
  }
}

async function isWebsiteReachable(url) {
  try {
    // Send a request to the URL
	console.log('Waiting ...')
    const response = await fetch(url, {
      method: 'HEAD', // Use HEAD to minimize data transfer (only headers are retrieved)
      mode: 'no-cors', // Avoid CORS issues with third-party websites (may still block for some URLs)
	  signal: AbortSignal.timeout(3000)
    });

    // Check if the response status is in the success range
    if (response.ok || response.status === 0) {
      return true;
    } else {
      return false;
    }
  } catch (error) {
    return false;
  }
}

isWebsiteReachable('https://www.youtube.com').then((reachable) => {
  if (!reachable) {
	console.log('Repalce')
	replaceVideoWithImage('videoyt1', './image/yt_YG7FTLDIqic_poster.jpg')
	replaceVideoWithImage('videoyt2', './image/yt_bk11g3hZX5s_poster.jpg')
	replaceVideoWithImage('videoyt3', './image/yt_VMV3MD1GIE_poster.jpg')
    replaceVideoWithImage('videoyt4', './image/yt_yKmkXJSlAl8_poster.jpg')
	replaceVideoWithImage('videoyt5', './image/yt_WmI7bv9nqjI_poster.jpg')
	replaceVideoWithImage('videoyt6', './image/yt_ZYSOonigv3s_poster.jpg')
  } else {
  }
});

</script>

<a id="members" class="anchor"></a>
<h2>Lab members</h2>

<table class="imgtable"><tbody>

<tr><td><div class="span3">
<img src="./image/chenxiao.jpg" width="150" height="150" alt="" /> <br />
<a href="https://xiao-chen.tech/" target="_blank"> Xiao Chen 陈骁 </a> <br /> Ph.D. candidate
</div></td>

<td><div class="span3">
<img src="./image/caixin.jpg" width="150" height="150" alt="" /> <br />
<a href="https://caixin98.github.io/" target="_blank"> Xin Cai 蔡昕 </a> <br /> Ph.D. candidate
</div></td>

<td><div class="span3">
<img src="./image/dinglihe.jpg" width="150" height="150" alt="" /> <br />
<a href="https://dinglihe.github.io/" target="_blank"> Lihe Ding 丁立鹤 </a> <br /> Ph.D. candidate
</div></td>

<td><div class="span3">
<img src="./image/youzhiyuan.png" width="150" height="150" alt="" /> <br />
<a href="https://zhiyuanyou.github.io/" target="_blank"> Zhiyuan You 尤志远 </a><br />
Ph.D. candidate <br />
(Co. w. Chao Dong)
</div></td>

<td><div class="span3">
<img src="./image/denghongyu.jpg" width="150" height="150" alt="" /> <br />
Hongyu Deng 邓宏宇 <br /> Ph.D. candidate  <br />
(Co. w. He Chen)
</div></td>


</tr>
<tr>

<td><div class="span3">
<img src="./image/chen_yutian.jpg" width="150" height="150" alt="" /> <br />
<a href="https://yutian10.github.io/" target="_blank"> Yutian Chen 陈羽田 </a><br />
Ph.D. candidate <br />
</div></td>

<td><div class="span3">
<img src="./image/li_ruikang.jpg" width="150" height="150" alt="" /> <br />
<a href="https://lyricccco.github.io/" target="_blank"> Ruikang Li 李睿康 </a><br />
Ph.D. candidate <br />
</div></td>	

<td><div class="span3">
<img src="./image/linhua_huang.jpg" width="150" height="150" alt="" /> <br />
<a href="https://" target="_blank"> Linhua Huang 黄霖华 </a><br />
Ph.D. candidate <br />
</div></td>	

<td><div class="span3">
<img src="./image/wu_jiarui.jpg" width="150" height="150" alt="" /> <br />
<a href="https://gnwekge78707.github.io/" target="_blank"> Jiarui Wu 吴佳锐 </a><br />
Ph.D. candidate <br />
</div></td>	

<td><div class="span3">
<img src="./image/chenjian_gao.jpg" width="150" height="150" alt="" /> <br />
<a href="https://cjeen.github.io/" target="_blank"> Chenjian Gao 高宸健 </a><br />
Ph.D. candidate <br />
</div></td>

</tr>
<tr>

<td><div class="span3">
<img src="./image/luo_yawen.jpg" width="150" height="150" alt="" /> <br />
<a href="https://" target="_blank"> Yawen Luo 罗亚文 </a><br />
Ph.D. candidate <br />
</div></td>	

<td><div class="span3">
<img src="./image/chen_zixuan.jpg" width="150" height="150" alt="" /> <br />
<a href="https://scholar.google.com/citations?user=pwixOhcAAAAJ&hl=zh-CN" target="_blank"> Zixuan Chen 陈子轩 </a><br />
Ph.D. candidate <br />
</div></td>	

<td><div class="span3">
<img src="./image/ma_yongrui.jpg" width="150" height="150" alt="" /> <br />
<a href="https://sites.google.com/view/yongrayma" target="_blank"> Yongrui Ma 马咏芮 </a><br />
co. w. Qi Dou & Jinwei Gu <br />
</div></td>	

<td><div class="span3">
<img src="./image/li_lingen.jpg" width="150" height="150" alt="" /> <br />
<a href="https://lg-li.github.io" target="_blank"> Lingen Li 李林根 </a><br />
co. w. Qi Dou & Jinwei Gu <br />
</div></td>

<td><div class="span3">
<img src="./image/jiang_yitong.jpg" width="150" height="150" alt="" /> <br />
<a href="https://scholar.google.com/citations?user=5gStTm4AAAAJ&hl=en" target="_blank"> Yitong Jiang 蒋依桐 </a><br />
co. w. Qi Dou & Jinwei Gu <br />
</div></td>




</tr>	
	
</table>

<h2>Postdoc and Visiting Scholars</h2>

<table class="imgtable"><tbody>

<!--
<td><div class="span3">
<img src="./image/yaokun_li.jpg" width="150" height="150" alt="" /> <br />
<a href="https://scholar.google.com/citations?user=plCD9wwAAAAJ" target="_blank"> Yaokun Li 李垚坤 </a><br />
</div></td>
-->

<td><div class="span3">
<img src="./image/mingde_yao.jpg" width="150" height="150" alt="" /> <br />
<a href="https://mdyao.github.io/" target="_blank"> Mingde Yao 姚明德 </a><br />
</div></td>

<td><div class="span3">
<img src="./image/chen_ao.jpg" width="150" height="150" alt="" /> <br />
<a href="https://openreview.net/profile?id=%7EAo_Chen5" target="_blank"> Ao Chen 陈鳌 </a><br />
</div></td>

<td><div class="span3">
<img src="./image/junhao_zhuang.jpg" width="150" height="150" alt="" /> <br />
<a href="https://zhuang2002.github.io/" target="_blank"> Junhao Zhuang 庄俊豪 </a><br />
</div></td>

<td><div class="span3">
<img src="./image/jiahao_zhan.jpg" width="150" height="150" alt="" /> <br />
<a href="https://johnzhan2023.github.io/" target="_blank"> Jiahao Zhan 詹佳豪 </a><br />
</div></td>

<td><div class="span3">
<img src="./image/ruchang_yao.jpg" width="150" height="150" alt="" /> <br />
<a href="https://www.ruchangyao.xyz" target="_blank"> Ruchang Yao 姚汝昌 </a><br />
</div></td>

</tr>

</table>	

<h2>Alumni</h2>

<ul>
  <li><a href="https://iron-lyk.github.io/" target="_blank"> Yaokun Li (李垚坤) </a></li>
  <li><a href="https://yuehaowang.github.io/" target="_blank"> Yuehao Wang (王跃豪) </a>, currently is a Ph.D. student at U.T. Austin</li>
  <li><a href="https://sky-lzy.github.io/" target="_blank"> Zhiyi Li (李智毅) </a>, currently is a Ph.D. student at MIT.</li>
  <li>Zhuoya Wang (王卓雅), currently is a master student at Tsinghua University.</li>
</ul>

<!-- ######################################################################################################################## -->
<!-- Project -->
<script>
function addImageSwitcher(projName) {
  const trEle = document.getElementById(projName + '_tr');
  const twoEle = document.getElementById(projName + '_two')
  const oneEle = document.getElementById(projName + '_one')
  trEle.onmouseout = function () {
    twoEle.style.opacity = '0';
    oneEle.style.opacity = '1';
  };
  trEle.onmouseover = function () {
    twoEle.style.opacity = '1';
    oneEle.style.opacity = '0';
  };
  oneEle.style.opacity = '1';
  twoEle.style.opacity = '0';
  console.log(projName + '_image')
  console.log(trEle)
  console.log(imgEle)
}
</script>


<a id="publications_recent" class="anchor"></a>
<h2>Selected Publications (Recent 3 years)</h2>

<table class="imgtable">
<tbody>
<tr>
<td>
<h3>2026</h3>
</td>
</tr>

<tr id='flashvsr_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='flashvsr_two' style='height=160px'>
	  <video width=125% muted autoplay loop><source class='proj_thumb' src='image/2025_flashvsr.mp4' type='video/mp4' ></video>
	  </div>
    <img class="proj_thumb" id='flashvsr_one' src="image/2025_flashvsr.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('flashvsr') </script>
</td>
<td><p class="pub_title"> FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution </p>
  <p class="pub_author"> Junhao Zhuang, Shi Guo, Xin Cai, Xiaohui Li, Yihao Liu, Chun Yuan, <b>Tianfan Xue</b>&#8224<br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2026 <br>
[<a href="https://arxiv.org/pdf/2510.12747">PDF</a>] [<a href="https://zhuang2002.github.io/FlashVSR/">Website</a>] [<a href="https://huggingface.co/JunhaoZhuang/FlashVSR">Code</a>]
</p>
</td>
</tr>

<tr id='davae_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='davae_two' style="height=160px"><img class='proj_thumb' src='image/2026-davae-plot.jpg'></div>
    <img class="proj_thumb" id='davae_one' src="image/2026-davae-input.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('davae') </script>
</td>
<td><p class="pub_title"> DA-VAE: Plug-in Latent Compression for Diffusion via Detail Alignment </p>
  <p class="pub_author">Xin Cai, Zhiyuan You, Zhoutong Zhang, <b>Tianfan Xue</b><br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2026. <br> 
[<a href="https://caixin98.github.io/papers/davae/paper.pdf">PDF</a>]
</p>
</td>
</tr>

<tr id='dynamictree_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='dynamictree_two' style='height=160px'>
	  <video width=100% muted autoplay loop><source class='proj_thumb' src='image/2026-dynamictree.mp4' type='video/mp4' ></video>
	</div>
    <img class="proj_thumb" id="dynamictree_one" src="image/2026-dynamictree.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('dynamictree') </script>
</td>
<td><p class="pub_title"> DynamicTree: Interactive Real Tree Animation via Sparse Voxel Spectrum </p>
  <p class="pub_author">Yaokun Li, Lihe Ding, Xiao Chen, Guang Tan, <b>Tianfan Xue</b><br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2026 <br> 
[<a href="https://lg-li.github.io/project/cubecomposer/">Website</a>] [<a href="https://lg-li.github.io/pub-videos/CubeComposer/li2026cubecomposer-video.mp4">Video</a>]
</p>
</td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/2026-instantretouch.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> InstantRetouch: Efficient and High-Fidelity Instruction-Guided Image Retouching with Bilateral Space </p>
<p class="pub_author"> Jiarui Wu, Yujin Wang, Ruikang Li, Fan Zhang, Mingde Yao, <b>Tianfan Xue</b> <br>
Computer Vision and Pattern Recognition (<b>CVPR</b>), 2026 <br>
[<a href="https://gnwekge78707.github.io/papers/DistilledBilateral___CVPR_2026__arxiv_.pdf">PDF</a>]</p></td>
</tr>

<tr id='cubecomposer_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='cubecomposer_two' style='height=160px'>
	<video width=115% muted autoplay loop><source class='proj_thumb' src='image/2026-cubecomposer-video.mp4' type='video/mp4' ></video>
	</div>
    <img class="proj_thumb" id="cubecomposer_one" src="image/2026-cubecomposer.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('cubecomposer') </script>
</td>
<td><p class="pub_title"> CubeComposer: Spatio-Temporal Autoregressive 4K 360° Video Generation from Perspective Video </p>
  <p class="pub_author">Lingen Li, Guangzhi Wang, Xiaoyu Li, Zhaoyang Zhang, Qi Dou, Jinwei Gu, <b>Tianfan Xue</b>, Ying Shan<br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2026 <br> 
[<a href="https://lg-li.github.io/project/cubecomposer/">Website</a>] [<a href="https://lg-li.github.io/pub-videos/CubeComposer/li2026cubecomposer-video.mp4">Video</a>]
</p>
</td>
</tr>

<tr id='arvfi_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='arvfi_two' style="height=160px"><img class='proj_thumb' src='image/2026-arvfi-net.jpg'></div>
    <img class="proj_thumb" id='arvfi_one' src="image/2026-arvfi.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('arvfi') </script>
</td>
<td><p class="pub_title"> Bi-directional Autoregressive Diffusion for Large Complex Motion Interpolation </p>
  <p class="pub_author">Yongrui Ma, Shijie Zhao, Mingde Yao, Junlin Li, Li zhang, Xiaohong Liu, Qi Dou, Jinwei Gu, <b>Tianfan Xue</b><br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2026 <br> 
</p>
</td>
</tr>


<tr id='photoframer_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='photoframer_two' style='height=160px'><img class='proj_thumb' src='image/2026_photoframer_output.jpg'></div>
    <img class="proj_thumb" id='photoframer_one' src="image/2026_photoframer_input.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('photoframer') </script>
</td>
<td><p class="pub_title"> PhotoFramer: Multi-modal Image Composition Instruction </p>
  <p class="pub_author">Zhiyuan You, Ke Wang, He Zhang, Xin Cai, Jinjin Gu, <b>Tianfan Xue</b>, Chao Dong, Zhoutong Zhang<br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2026. <br> 
[<a href="https://arxiv.org/abs/2512.00993">PDF</a>] [<a href="https://zhiyuanyou.github.io/photoframer/">Website</a>]
</p>
</td>
</tr>

	
<tr>
  <td><img class="proj_thumb" src="./image/2026_cgspn.jpg" alt=""/>&nbsp;</td>
  <td><p class="pub_title"> Scaling Parallel Sequence Models to Vision Foundation Models </p>
  <p class="pub_author"> Jiarui Wu, Yujin Wang, Ruikang Li, Fan Zhang, Mingde Yao, <b>Tianfan Xue</b> <br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2026 </p>
  </td>
</tr>

<tr id='fullpart_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='fullpart_two' style='height=160px'>
	<video width=115% muted autoplay loop><source class='proj_thumb' src='image/2026-fullpart.mp4' type='video/mp4' ></video>
	</div>
    <img class="proj_thumb" id="fullpart_one" src="image/2026-fullpart.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('fullpart') </script>
</td>
<td><p class="pub_title"> FullPart: Generating each 3D Part at Full Resolution </p>
  <p class="pub_author"> Lihe Ding, Shaocong Dong, Yaokun Li, Chenjian Gao, Xiao Chen, Rui Han, Yihao Kuang, Hong Zhang, Bo Huang, Zhanpeng Huang, Zibin Wang, Dan Xu&#8224, <b>Tianfan Xue</b>&#8224<br>
  International Conference on Learning Representations (<b>ICLR</b>), 2026 <br>
  [<a href="https://arxiv.org/abs/2510.26140">PDF</a>] [<a href="https://github.com/hkdsc/fullpart">Website</a>] [<a href="https://fullpart3d.github.io/">Code</a>] [<a href="https://huggingface.co/datasets/dscdyc/partversexl">Dataset</a>]
</p>
</td>
</tr>

<tr id='s2rhdr_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='s2rhdr_two' style='height=160px'>
	  <img class="proj_thumb" src="image/2026-s2r-hdr.gif">
	</div>
    <img class="proj_thumb" id="s2rhdr_one" src="image/2026-s2r-hdr.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('s2rhdr') </script>
</td>
<td><p class="pub_title"> S2R-HDR: A Large-Scale Rendered Dataset for HDR Fusion </p>
  <p class="pub_author"> Yujin Wang, Jiarui Wu, Yichen Bian, Fan Zhang, <b>Tianfan Xue</b><br>
  International Conference on Learning Representations (<b>ICLR</b>), 2026 <br>
  [<a href="https://arxiv.org/abs/2504.07667">PDF</a>] [<a href="https://openimaginglab.github.io/S2R-HDR/">Website</a>] [<a href="https://huggingface.co/datasets/iimmortall/S2R-HDR">Dataset (part 1)</a>] [<a href="https://huggingface.co/datasets/iimmortall/S2R-HDR">Dataset (part 2)</a>]
</p>
</td>
</tr>

<tr id='loraedit_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='loraedit_two' style='height=160px'>
	<video width=115% muted autoplay loop><source class='proj_thumb' src='image/2026-loraedit.mp4' type='video/mp4' ></video>
	</div>
    <img class="proj_thumb" id="loraedit_one" src="image/2026-loraedit.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('loraedit') </script>
</td>
<td><p class="pub_title"> LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware LoRA Fine-Tuning </p>
  <p class="pub_author"> Chenjian Gao, Lihe Ding, Xin Cai, Zhanpeng Huang, Zibin Wang, <b>Tianfan Xue</b><br>
  International Conference on Learning Representations (<b>ICLR</b>), 2026 <br>
  [<a href="https://arxiv.org/abs/2506.10082">PDF</a>] [<a href="https://cjeen.github.io/LoRAEdit/">Website</a>]
</p>
</td>
</tr>

<tr id='realtime_vfi'>
<td><img class="proj_thumb" src="./image/2026-realtime-vfi.jpg" alt=""/>&nbsp;</td>

<td><p class="pub_title"> Realtime Video Frame Interpolation using One-Step Diffusion Sampling </p>
  <p class="pub_author"> Yongrui Ma, Shijie Zhao, Mingde Yao, Junlin Li, Li zhang, Xiaohong Liu, Qi Dou, Jinwei Gu, <b>Tianfan Xue</b><br>
  International Conference on Learning Representations (<b>ICLR</b>), 2026 <br>
</p>
</td>
</tr>

<tr id='rliqa_tr'>
<td><img class="proj_thumb" src="./image/2026-rl-iqa.jpg" alt=""/>&nbsp;</td>

<td><p class="pub_title"> Reasoning as Representation: Rethinking Visual Reinforcement Learning in Image Quality Assessment </p>
  <p class="pub_author"> Shijie Zhao, Xuanyu Zhang, Weiqi Li, Junlin Li, Li Zhang, <b>Tianfan Xue</b>, Jian Zhang<br>
  International Conference on Learning Representations (<b>ICLR</b>), 2026 <br>
</p>
</td>
</tr>

<tr id='tooncomposer_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='tooncomposer_two' style='height=160px'><img class='proj_thumb' src='image/2025-tooncomposer.gif'></div>
    <img class="proj_thumb" id='tooncomposer_one' src="image/2025-tooncomposer.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('tooncomposer') </script>
</td>
<td><p class="pub_title"> ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing </p>
  <p class="pub_author">Lingen Li, Guangzhi Wang&#8224, Zhaoyang Zhang, Yaowei Li, Xiaoyu Li, Qi Dou, Jinwei Gu, <b>Tianfan Xue&#8224</b>, Ying Shan<br>
  International Conference on Learning Representations (<b>ICLR</b>), 2026 <br>
[<a href="https://arxiv.org/pdf/2508.10881">PDF</a>] [<a href="https://lg-li.github.io/project/tooncomposer/">Website</a>] [<a href="https://github.com/hkdsc/copart">Code</a>] [<a href="https://huggingface.co/datasets/dscdyc/partverse">Data</a>]  [<a href="https://huggingface.co/papers/2507.08772">huggingface</a>]
</p>
</td>
</tr>

<tr>
<td>
<h3>2025</h3>
</td>
</tr>

<tr id='camclonemaster_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='camclonemaster_two' style='height=160px'>
	<video width=115% muted autoplay loop><source class='proj_thumb' src='image/2025_camclonemaster.mp4' type='video/mp4' ></video>
	</div>
    <img class="proj_thumb" id="camclonemaster_one" src="image/2025_camclonemaster.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('camclonemaster') </script>
</td>
<td><p class="pub_title"> CamCloneMaster: Enabling Reference-based Camera Control for Video Generation </p>
  <p class="pub_author">Yawen Luo, Xiaoyu Shi&#8224, Jianhong Bai, Menghan Xia, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai, <b>Tianfan Xue</b>&#8224<br>
  ACM <b>SIGGRAPH Asia</b>, 2025 <br>
[<a href="https://arxiv.org/pdf/2506.03140">PDF</a>] [<a href="https://camclonemaster.github.io/">Website</a>] [<a href="https://huggingface.co/datasets/KwaiVGI/CameraClone-Dataset">Data</a>]
</p>
</td>
</tr>

<tr id='4dslomo_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='4dslomo_two' style='height=160px'>
	<video width=112% muted autoplay loop><source class='proj_thumb' src='image/2025-4DSloMo.mp4' type='video/mp4' ></video>
	</div>
    <img class="proj_thumb" id="4dslomo_one" src="image/2025-4DSloMo.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('4dslomo') </script>
</td>
<td><p class="pub_title"> 4DSloMo: 4D Reconstruction for High Speed Scene with Asynchronous Capture </p>
  <p class="pub_author">Yutian Chen, Shi Guo, Tianshuo Yang, Lihe Ding, Xiuyuan Yu, Jinwei Gu, <b>Tianfan Xue</b><br>
  ACM <b>SIGGRAPH Asia</b>, 2025 <br>
[<a href="https://arxiv.org/pdf/2507.05163">PDF</a>] [<a href="https://openimaginglab.github.io/4DSloMo/">Website</a>] [<a href="https://github.com/OpenImagingLab/4DSloMo">Code</a>]
</p>
</td>
</tr>

<tr id='copart_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='copart_two' style='height=160px'><img class='proj_thumb' src='image/2025-copart.gif'></div>
    <img class="proj_thumb" id='copart_one' src="image/2025-copart.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('copart') </script>
</td>
<td><p class="pub_title"> From One to More: Contextual Part Latents for 3D Generation (CoPart) </p>
  <p class="pub_author">Shaocong Dong*, Lihe Ding*, Xiao Chen, Yaokun Li, Yuxin Wang, Yucheng Wang, Qi Wang, Jaehyeok Kim, Chenjian Gao, Zhanpeng Huang, Zibin Wang, <b>Tianfan Xue&#8224</b>, Dan Xu&#8224<br>
  International Conference on Computer Vision (<b>ICCV</b>), 2025 <br>
[<a href="https://arxiv.org/pdf/2506.10082">PDF</a>] [<a href="https://hkdsc.github.io/project/copart/">Website</a>] [<a href="https://github.com/hkdsc/copart">Code</a>] [<a href="https://huggingface.co/datasets/dscdyc/partverse">Data</a>]  [<a href="https://huggingface.co/papers/2507.08772">huggingface</a>]
</p>
</td>
</tr>

<tr id='wrist_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='wrist_two' style='height=160px'><img class='proj_thumb' src='image/2025-wrist-output.gif'></div>
    <img class="proj_thumb" id='wrist_one' src="image/2025-bracelet-input.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('wrist') </script>
</td>
<td><p class="pub_title"> From Gallery to Wrist: Realistic 3D Bracelet Insertion in Videos </p>
  <p class="pub_author">Chenjian Gao, Lihe Ding, Xin Cai, Zhanpeng Huang, Zibin Wang <b>Tianfan Xue</b><br>
  International Conference on Computer Vision (<b>ICCV</b>), 2025 <br>
[<a href="https://arxiv.org/pdf/2507.20331">PDF</a>] [<a href="https://cjeen.github.io/BraceletPaper/">Website</a>]
</p>
</td>
</tr>

<tr id='gleam_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='gleam_two' style='height=160px'><img class='proj_thumb' src='image/2025-gleam.gif'></div>
    <img class="proj_thumb" id='gleam_one' src="image/2025-gleam.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('gleam') </script>
</td>
<td><p class="pub_title"> GLEAM: Learning Generalizable Exploration Policy for Active Mapping in Complex 3D Indoor Scenes </p>
  <p class="pub_author">Xiao Chen, Tai Wang, Quanyi Li, Tao Huang, Jiangmiao Pang, <b>Tianfan Xue</b><br>
  International Conference on Computer Vision (<b>ICCV</b>), 2025 <br>
[<a href="https://arxiv.org/pdf/2505.20294">PDF</a>] [<a href="https://xiao-chen.tech/gleam/">Website</a>] [<a href="https://github.com/zjwzcx/GLEAM">Code</a>] [<a href="https://github.com/zjwzcx/GLEAM/tree/master/data">Data</a>] [<a href="https://www.youtube.com/watch?v=hOk8TJiotag">YouTube</a>] [<a href="https://www.bilibili.com/video/BV1n2jqzeE6N">Bilibili</a>]
</p>
</td>
</tr>

<tr id='adaptiveae_tr'>
<td><img class="proj_thumb" src="./image/2025_adaptiveae.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> AdaptiveAE: An Adaptive Exposure Strategy for HDR Capturing in Dynamic Scenes </p>
  <p class="pub_author">Tianyi Xu, Fan Zhang, Boxin Shi&#8224, <b>Tianfan Xue&#8224</b>, Yujin Wang <br>
  International Conference on Computer Vision (<b>ICCV</b>), 2025.
  [<a href="https://arxiv.org/pdf/2504.04126">PDF</a>] [<a href="https://openimaginglab.github.io/AdaptiveAE/">Webpage</a>]
</p>
</td>
</tr>

<tr id='struct_video_tr'>
<td><img class="proj_thumb" src="./image/2025_struct_video.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Multi-identity Human Image Animation with Structural Video Diffusion </p>
  <p class="pub_author">Zhenzhi Wang, Yixuan Li, Yanhong Zeng, Yuwei Guo, Dahua Lin, <b>Tianfan Xue</b>, Bo Dai<br>
  International Conference on Computer Vision (<b>ICCV</b>), 2025.
  [<a href="https://arxiv.org/pdf/2504.04126">PDF</a>] [<a href="https://github.com/zhenzhiwang/Multi-HumanVid">Code</a>]
</p>
</td>
</tr>

<tr id='token_eff_llm_tr'>
<td><img class="proj_thumb" src="./image/2025_token_eff_llm.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Token-Efficient VLM: High-Resolution Image Understanding via Dynamic Region Proposal </p>
  <p class="pub_author">Yitong jiang, Jinwei Gu, <b>Tianfan Xue</b>, Ka Chun Cheung, Pavlo Molchanov, Hongxu Yin, Sifei Liu<br>
  International Conference on Computer Vision (<b>ICCV</b>), 2025.
</p>
</td>
</tr>

<tr id='uniisp_tr'>
<td><img class="proj_thumb" src="./image/2025-UNIISP.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Uni-ISP: Unifying the Learning of ISPs from Multiple Cameras </p>
  <p class="pub_author">Lingen Li, Mingde Yao, Xingyu Meng, Muquan Yu, <b>Tianfan Xue</b>, and Jinwei Gu<br> Transaction on Image Processing (<b>TIP</b>), 2025. <br> 
  [<a href="https://arxiv.org/pdf/2406.01003">PDF</a>] [<a href="https://lg-li.github.io/dataset/five-cam">Data</a>] [<a href="https://lg-li.github.io/project/uni-isp/">Webpage</a>]
</p>
</td>
</tr>

<tr id='ultrafusion_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='ultrafusion_two' style='height=160px'><img class='proj_thumb' src='image/2024-ultrafusion-result.jpg'></div>
    <img class="proj_thumb" id='ultrafusion_one' src="image/2024-ultrafusion-input.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('ultrafusion') </script>
</td>
<td><p class="pub_title"> UltraFusion: Ultra High Dynamic Imaging using Exposure Fusion </p>
  <p class="pub_author">Zixuan Chen*, Yujin Wang*, Xin Cai, Zhiyuan You, Zheming Lu, Fan Zhang, Shi Guo, <b>Tianfan Xue</b><br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), <b>Spotlight</b>, 2025 <br>
  <b>Try online demo</b> at: <a href="https://huggingface.co/spaces/iimmortall/UltraFusion">Huggingface</a> </br>
[<a href="https://arxiv.org/pdf/2501.11515">PDF</a>] [<a href="https://github.com/OpenImagingLab/UltraFusion">Code</a>] [<a href="https://openimaginglab.github.io/UltraFusion/">Website</a>] [<a href="https://ultrafusion.intern-ai.org.cn/home">Demo Page</a>]
</p>
  <p style="color:blue;"><b>CVPR Best Demo Honorable Mention</b></p>
</td>
</tr>

<tr id='deqa_score_tr'>
<td><img class="proj_thumb" src="./image/2025-deqa-score.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Teaching Large Language Models to Regress Accurate Image Quality Scores using Score Distribution </p>
  <p class="pub_author">Zhiyuan You, Xin Cai, Jinjin Gu, <b>Tianfan Xue&#8224</b>, Chao Dong&#8224 <br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2025. <br> 
  [<a href="https://arxiv.org/abs/2501.11561">PDF</a>] [<a href="https://github.com/zhiyuanyou/DeQA-Score">Code</a>] [<a href="https://huggingface.co/datasets/zhiyuanyou/Data-DeQA-Score">Data</a>] [<a href="https://depictqa.github.io/deqa-score/">Website</a>]
</p>
</td>
</tr>

<tr id='nvcomposer_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='nvcomposer_two' style='height=160px'><img class='proj_thumb' src='image/2025-nvcomposer.gif'></div>
    <img class="proj_thumb" id='nvcomposer_one' src="image/2025-nvcomposer.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('nvcomposer') </script>
</td>
<td><p class="pub_title"> NVComposer: Boosting Generative Novel View Synthesis with Multiple Sparse and Unposed Images </p>
  <p class="pub_author">Lingen Li, Zhaoyang Zhang&#8224, Yaowei Li, Jiale Xu, Wenbo Hu, Xiaoyu Li, Weihao Cheng, Jinwei Gu, <b>Tianfan Xue&#8224</b>, Ying Shan <br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2025. <br> 
  Try online demo at: <a href="https://huggingface.co/spaces/TencentARC/NVComposer">Huggingface</a> <br>
  [<a href="https://arxiv.org/pdf/2501.11515">PDF</a>] [<a href="https://github.com/TencentARC/NVComposer">Github</a>] [<a href="https://lg-li.github.io/project/nvcomposer">Website</a>]
</p>
</td>
</tr>

<tr id='polarfree_tr'>
<td><img class="proj_thumb" src="./image/2025-polarfree.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> PolarFree: Polarization-based Reflection-Free Imaging </p>
  <p class="pub_author">Mingde Yao, Menglu Wang, King-Man Tam, Lingen Li, <b>Tianfan Xue</b>, Jinwei Gu. <br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2025. <br> 
  [<a href="https://mdyao.github.io/PolarFree/">PDF</a>] [<a href="https://github.com/mdyao/PolarFree">Code</a>] [<a href="https://huggingface.co/datasets/Mingde/PolaRGB">Dataset</a>] [<a href="https://mdyao.github.io/PolarFree/">Website</a>]
</p>
</td>
</tr>

<tr id='bilateral-driving_tr'>
<td><img class="proj_thumb" src="./image/2025-bilateral-driving.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Unifying Appearance Codes and Bilateral Grids for Driving Scene Gaussian Splatting </p>
  <p class="pub_author">Nan Wang, Yuantao Chen, Lixing Xiao, Weiqing Xiao, Bohan Li, Zhaoxi Chen, Chongjie Ye, Shaocong Xu, Saining Zhang, Ziyang Yan, Pierre Merriaux, Lei Lei, <b>Tianfan Xue</b>, Hao Zhao&#8224. <br>
  Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2025. <br> 
  [<a href="https://bigcileng.github.io/bilateral-driving/static/bilateral-driving-arxiv.pdf">PDF</a>] [<a href="https://github.com/BigCiLeng/bilateral-driving">Code</a>] [<a href="https://bigcileng.github.io/bilateral-driving/">Website</a>]
</p>
</td>
</tr>

<tr id='cinemaster_tr'>
<td class="proj_cinemaster">
  <div class="one" style="height=160px">
    <div class="two" id='cinemaster_two' style='height=160px'><img class='proj_thumb' src='image/2025-cinemaster.gif'></div>
    <img class="proj_thumb" id='cinemaster_one' src="image/2025-cinemaster.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('cinemaster') </script>
</td>
<td><p class="pub_title"> A 3D-Aware and Controllable Framework for Cinematic Text-to-Video Generation </p>
  <p class="pub_author">Qinghe Wang*, Yawen Luo*, Xiaoyu Shi&#8224, Xu Jia&#8224, Huchuan Lu, <b>Tianfan Xue&#8224</b>, Xintao Wang, Pengfei Wan, Di Zhang, Kun Gai. <br>
  ACM <b>SIGGRAPH</b>, 2025. <br> 
  [<a href="https://arxiv.org/abs/2502.08639">PDF</a>] [<a href="https://cinemaster-dev.github.io/">Website</a>]
</p>
</td>
</tr>

<tr id='blur_learning_tr'>
<td><img class="proj_thumb" src="./image/2025-blur-learning.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> A Physics-Informed Blur Learning Framework for Imaging Systems </p>
  <p class="pub_author">Liqun Chen, Yuxuan Li, Jun Dai, Jinwei Gu, <b>Tianfan Xue</b><br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2025. <br> 
  [<a href="https://arxiv.org/pdf/2502.11382">PDF</a>]
</p>
</td>
</tr>

<tr>
<td>
<h3>2024</h3>
</td>
</tr>

<tr id='evshdr_tr'>
<td><img class="proj_thumb" src="./image/2024-evshdr.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Event-assisted 12-stop HDR Imaging of Dynamic Scene </p>
  <p class="pub_author">Shi Guo, Zixuan Chen, Ziran Zhang, Yutian Chen, Gangwei Xu, <b>Tianfan Xue</b><br>
  arXiv 2412.14705, 2024. <br> 
[<a href="https://arxiv.org/pdf/2412.14705">PDF</a>] [<a href="https://openimaginglab.github.io/Event-Assisted-12stops-HDR/">Website</a>]
</p>
</td>
</tr>

<tr id='phocolens_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
    <div class="two" id='phocolens_two' style='height=160px'><img class='proj_thumb' src='image/2024_phocolen_ours.png'></div>
    <img class="proj_thumb" id='phocolens_one'  src="image/2024_phocolen_base.png">
  </div>
  <script type="text/javascript">addImageSwitcher('phocolens') </script>
</td>
<td><p class="pub_title"> PhoCoLens: Photorealistic and Consistent Reconstruction in Lensless Imaging </p>
  <p class="pub_author">Xin Cai, Zhiyuan You, Hailong Zhang, Wentao Liu, Jinwei Gu, <b>Tianfan Xue</b><br>
  Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2024. <br> 
  <b>Spotlight</b> 
[<a href="https://arxiv.org/pdf/2409.17996">PDF</a>] [<a href="https://phocolens.github.io/">Webpage</a>]
</p>
</td>
</tr>

<tr id='rltuning_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
	<div class="two" id='rltuning_two' style="height=160px"><img class="proj_thumb" src="image/2024-rl-tuning-ours.jpg"></div>
	<img class="proj_thumb" id="rltuning_one" src="image/2024-rl-tuning-input.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('rltuning') </script>
</td>
<td>
  <p class="pub_title"> Goal Conditioned Reinforcement Learning for Photo Finishing Tuning </p>
  <p class="pub_author"> Jiarui Wu, Yujin Wang, Lingen Li, Zhang Fan, <b>Tianfan Xue</b><br>
  Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2024.<br>
  [<a href="https://openreview.net/pdf/3f8d40c2dcf5fa09bbe755497ee149774572ee7d.pdf">PDF</a>] [<a href="https://openimaginglab.github.io/RLPixTuner/">Webpage</a>] [<a href="https://openimaginglab.github.io/RLPixTuner/">Code</a>]  [<a href="https://www.youtube.com/watch?v=fFIkc3KHS28&t=42s">Video</a>]
</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/2024_adaptiveisp.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> AdaptiveISP: Learning an Adaptive Image Signal Processor for Object Detection </p>
  <p class="pub_author"> Yujin Wang, Xu Tian yi, Zhang Fan, <b>Tianfan Xue</b>, Jinwei Gu<br>
  Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2024. [<a href="https://arxiv.org/pdf/2410.22939">PDF</a>] [<a href="https://openimaginglab.github.io/AdaptiveISP/">Webpage</a>]
</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/2024_humanvid.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation </p>
  <p class="pub_author"> Zhenzhi Wang, Yixuan Li, Yanhong Zeng, Youqing Fang, Yuwei Guo, Wenran Liu, Jing Tan, Kai Chen, Bo Dai, <b>Tianfan Xue</b>, Dahua Lin<br>
  Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2024.
  [<a href="https://arxiv.org/pdf/2407.17438">PDF</a>] [<a href="https://humanvid.github.io/">Webpage</a>] [<a href="https://github.com/zhenzhiwang/HumanVid">Code</a>] [<a href="https://github.com/zhenzhiwang/HumanVid?tab=readme-ov-file#news">Data</a>]
</p></td>
</tr>

<tr id='dualdn_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
	<div class="two" id='dualdn_two' style="height=160px"><img class="proj_thumb" src="image/2024_dualdn_ours.jpg"></div>
	<img class="proj_thumb" id="dualdn_one" src="image/2024_dualdn_raw_denoise.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('dualdn') </script>
</td>
<td><p class="pub_title"> DualDn: Dual-domain Denoising via Differentiable ISP </p>
  <p class="pub_author"> Ruikang Li, Yujin Wang, Shiqi Chen, Fan Zhang, Jinwei Gu, <b>Tianfan Xue</b><br>
  European Conference on Computer Vision (<b>ECCV</b>), 2024.
  [<a href="https://arxiv.org/pdf/2409.18783">PDF</a>] [<a href="https://openimaginglab.github.io/DualDn/">Webpage</a>] [<a href="https://github.com/OpenImagingLab/DualDn">Code</a>]
</p>
</td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/2024-motion-mag-evs.gif" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Event-Based Motion Magnification </p>
  <p class="pub_author"> Yutian Chen*, Shi Guo*, Fangzheng Yu, Feng Zhang, Jinwei Gu, <b>Tianfan Xue</b><br>
  European Conference on Computer Vision (<b>ECCV</b>), 2024.
[<a href="https://arxiv.org/abs/2402.11957.pdf">PDF</a>] [<a href="https://openimaginglab.github.io/emm/">Webpage</a>] [<a href="https://github.com/OpenImagingLab/emm">Code</a>]
[<a href="https://youtu.be/WmI7bv9nqjI">YouTube</a>]
[<a href="https://www.bilibili.com/video/BV1ru4m1A76j/?share_source=copy_web&amp;vd_source=0d9d0742f4f6e5177a09abbf1bfc61da">Bilibili</a>]
</p></td>
</tr>

<tr id='depictqa_tr'>
<td class="proj_interactive" style="height=120px">
  <div class="one" style="height=160px">
	<div class="two" id='depictqa_two' style="height=160px"><img class="proj_thumb" src="image/2024_depictqa.jpg"></div>
	<img class="proj_thumb" id="depictqa_one" src="image/2024_depictqa_logo.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('depictqa') </script>
</td>
<td>
<p class="pub_title"> Descriptive Image Quality Assessment in the Wild </p>
<p class="pub_author"> Zhiyuan You, Jinjin Gu, Zheyuan Li, Xin Cai, Kaiwen Zhu, Chao Dong, <b>Tianfan Xue</b><br>
arXiv 2405.18842, 2024.
[<a href="https://depictqa.github.io/">Project</a>]
[<a href="https://depictqa.github.io/depictqa-wild/">Webpage</a>] [<a href="https://arxiv.org/pdf/2405.18842.pdf">PDF</a>] [<a href="https://github.com/XPixelGroup/DepictQA">Code</a>]
</p>
<p class="pub_title"> Depicting Beyond Scores:
Advancing Image Quality Assessment through Multi-modal Language Models
</p>
  <p class="pub_author"> Zhiyuan You*, Zheyuan Li*, Jinjin Gu*, Zhenfei Yin, <b>Tianfan Xue</b>, Chao Dong<br>
  European Conference on Computer Vision (<b>ECCV</b>), 2024.
[<a href="https://depictqa.github.io/depictqa-v1/">Webpage</a>] [<a href="https://arxiv.org/pdf/2312.08962.pdf">PDF</a>] [<a href="https://github.com/XPixelGroup/DepictQA">Code</a>]
</p>
</td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/2024-timelens-xl.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> TimeLens-XL: Real-time Event-based Video Frame Interpolation with Large Motion </p>
  <p class="pub_author"> Yongrui Ma, Shi Guo, Yutian Chen, <b>Tianfan Xue</b>, Jinwei Gu<br>
  European Conference on Computer Vision (<b>ECCV</b>), 2024.
[<a href="https://openimaginglab.github.io/TimeLens-XL/">PDF</a>] [<a href="https://openimaginglab.github.io/TimeLens-XL/">Webpage</a>] [<a href="https://github.com/OpenImagingLab/TimeLens-XL">Code</a>]
</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/2024_autodir.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> AutoDIR: Automatic All-in-One Image Restoration with Latent Diffusion </p>
  <p class="pub_author">Yitong Jiang, Zhaoyang Zhang, <b>Tianfan Xue</b>, Jinwei Gu<br>
  European Conference on Computer Vision (<b>ECCV</b>), 2024.
[<a href="https://arxiv.org/pdf/2310.10123.pdf">PDF</a>] [<a href="https://jiangyitong.github.io/AutoDIR_webpage/">Webpage</a>]
</p></td>
</tr>

<tr id='bilarf_tr'>
<td class="proj_interactive">
  <div class="one" style="height=160px">
	<div class="two" id='bilarf_two' style="height=160px"><video class="proj_thumb" muted autoplay loop><source src="image/2024_bilarf.mp4" type="video/mp4">Your browser does not support the video tag.</video></div>
	<img class="proj_thumb" id="bilarf_one" src="image/2024_bilarf.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('bilarf') </script>
</td>
<td><p class="pub_title"> Bilateral Guided Radiance Field Processing </p>
  <p class="pub_author"> Yuehao Wang, Chaoyi Wang, Bingchen Gong, <b>Tianfan Xue</b><br>
  <b>ACM SIGGRAPH</b>, 2024.
[<a href="https://arxiv.org/abs/2406.00448.pdf">PDF</a>] [<a href="https://bilarfpro.github.io/">Webpage</a>] 
[<a href="https://github.com/yuehaowang/bilarf/">Code</a>] [<a href="https://huggingface.co/datasets/Yuehao/bilarf_data/">Data</a>] 
</p>
<p style="color:blue;"><b>SIGGRAPH Honorable Mention</b></p>
</td>
</tr>

<tr id='lensless_face_tr'>
<td class="proj_interactive">
  <div class="one" style="height=80px">
	<div class="two" id='lensless_face_two' style="height=80px">
		<video class="proj_thumb" muted autoplay loop><source src="image/2024_lensless_face.mp4" type="video/mp4">Your browser does not support the video tag.</video>
	</div>
	<img class="proj_thumb" id="lensless_face_one" src="image/2024_lensless_face.jpg">
  </div>
  <script type="text/javascript">addImageSwitcher('lensless_face') </script>
</td>
<td><p class="pub_title"> LenslessFace : An End-to-End Optimized Lensless System for Privacy-Preserving Face Verification </p>
  <p class="pub_author"> Xin Cai, Hailong Zhang, Chenchen Wang, Wentao Liu, Jinwei Gu, <b>Tianfan Xue</b><br>
  arXiv 2406.04129, 2024.
[<a href="https://arxiv.org/abs/2406.04129.pdf">PDF</a>] [<a href="https://github.com/OpenImagingLab/">Webpage</a>]  [<a href="https://github.com/OpenImagingLab/LenslessFace">Code</a>]
</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/2024_gennbv.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction </p>
  <p class="pub_author"> Xiao Chen, Quanyi Li, Tai Wang, <b>Tianfan Xue</b>, Jiangmiao Pang<br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.
[<a href="https://arxiv.org/abs/2402.16174.pdf">PDF</a>] [<a href="https://gennbv.tech/">Webpage</a>] [<a href="https://www.youtube.com/watch?v=GP0PdaXs93E">YouTube</a>]
</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/eagle2.gif" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Text-to-3D Generation with Bidirectional Diffusion using both 2D and 3D priors </p>
  <p class="pub_author"> Lihe Ding*, Shaocong Dong*, Zhanpeng Huang, Zibin Wang, Yiyuan Zhang, Kaixiong Gong, Dan Xu, <b>Tianfan Xue</b><br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.
[<a href="https://arxiv.org/pdf/2312.04963.pdf">PDF</a>] [<a href="https://bidiff.github.io/">Webpage</a>]</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/2024_inter_gen.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Interactive3D: Create What You Want by Interactive 3D Generation </p>
  <p class="pub_author"> Shaocong Dong*, Lihe Ding*, Zhanpeng Huang, Zibin Wang, <b>Tianfan Xue</b>, Dan Xu<br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.
  [<a href="https://arxiv.org/pdf/2404.16510.pdf">PDF</a>]
  [<a href="https://interactive-3d.github.io/">Webpage</a>]
  [<a href="https://www.youtube.com/watch?v=ZYSOonigv3s">YouTube</a>]
  </p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/2024_video_hdr.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> HDRFlow: Real-Time HDR Video Reconstruction with Large Motions </p>
  <p class="pub_author"> Gangwei Xu*, Yujin Wang*, Jinwei Gu, <b>Tianfan Xue</b>, Xin Yang<br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.
  [<a href="https://arxiv.org/pdf/2403.03447.pdf">PDF</a>] [<a href="https://github.com/OpenImagingLab/HDRFlow">Webpage</a>]
  </p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/2024_embodiedscan.gif" alt=""/>&nbsp;</td>
<td><p class="pub_title"> EmbodiedScan: A Holistic Multi-Modal 3D Perception Suite Towards Embodied AI </p>
  <p class="pub_author"> Tai Wang*, Xiaohan Mao*, Chenming Zhu*, Runsen Xu, Ruiyuan Lyu, Peisen Li, Xiao Chen, Wenwei Zhang, Kai Chen, <b>Tianfan Xue</b>, Xihui Liu, Cewu Lu, Dahua Lin, Jiangmiao Pang<br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.
[<a href="https://arxiv.org/abs/2312.16170.pdf">PDF</a>] [<a href="https://tai-wang.github.io/embodiedscan/">Webpage</a>] [<a href="https://tai-wang.github.io/embodiedscan/">Code&amp;Data</a>]
</p></td>
</tr>


</tbody>
</table>









<!-- Education -->
<a id="education" class="anchor"></a>
<h2>Education</h2>
<ul>
<li><p><b>Ph.D., Computer Sci., Massachusetts Institute of Technology</b>,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aug. 2012 - Jul. 2017<br />
Supervisor: Prof. William T. Freeman.<br /></p>
</li>
</ul>
<ul>
<li><p><b>M.Phil., Information Eng., Chinese University of Hong Kong</b>,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aug. 2009 - Jul. 2011<br />
Supervisor: Prof. Xiaoou Tang<br /></p>
</li>
</ul>
<ul>
<li><p><b>B. Eng., Computer Sci. & Tech, Tsinghua University, China</b>,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Aug. 2005 - Jul. 2009 <br /></p>
</li>
</ul>

<!-- Other Projects 

<p><h3>Human Tracking using Online-Offline detector </h3></p>
<table class="imgtable"><tr><td>
<img class="proj_thumb" src="./image/tracking_small.jpg" alt=""/>&nbsp;</td>
<td align="left"><p><a name="tracking"></a>
We designed a human tracking framework combining an online detector using color histogram, and an offline detector using HOG, in which occlusion cases are dealt with by a novel EM algorithm. The project won <i>Outstanding undergraduate thesis</i> of Computer Science and Engineering Department, Tsinghua Univ. [<a href="./human_tracking.ppt">PPT</a>].<br /></p>
-->


<!-- Services -->

<a href="#publication"><h2>Services</h2></a>
<ul>
<li><p>Conference Organizers:</br>
Computer Vision and Pattern Recognition 2020 web chair</br>
Computer Vision and Pattern Recognition 2023, 2024 area chair</br>
Winter Conference on Applications of Computer Vision 2023 area chair</br>
<li><p>Conference Reviewers:</br>
Computer Vision and Pattern Recognition (CVPR): 2016, 2017, 2018, 2020, 2021, 2022</br>
European Conference on Computer Vision (ECCV): 2016, 2018, 2020, 2022, workshop on optical flow (2018)</br>
Pacific Graphics 2018</br>
International Conference on Computer Vision (ICCV) 2017, 2019, 2021</br>
SIGGRAPH 2018, 2021, 2022</br>
SIGGRAPH Asia 2017, 2021, 2022</br>
Neural Information Processing Systems (NeurIPS) 2016, 2021, 2022</br>
International Symposium on Circuits &amp; Systems (ISCAS) 2017</br>
<li><p>Journal Reviewers:</br>
IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)</br>
IEEE Transactions on Systems, Man, and Cybernetics </br>
IEEE Transactions on Computational Imaging (TCI) </br>
IEEE Transactions on Multimedia (TMM) </br>
IEEE Transactions on Image Processing (TIP) </br>
IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) </br>
Artificial Intelligence</br>
Image and Vision Computing (IVC)</br>
Cognitive Computation </br>
Computers and Electrical Engineering </br>
Machine Vision and Applications </br>
IEEE Computer Graphics and Applications </br>
Journal of the Optical Society of America </br>
Pattern Recognition Letter</br>
Optics and Lasers in Engineering</br>
</li>
</ul> 










<table class="imgtable">
<tbody>

<a id="publications_others" class="anchor"></a>
<h2>Selected Publications (others)</h2>

<tr>
<td><img class="proj_thumb" src="./image/2023_objnerf.gif" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Obj-NeRF: Extracting Object NeRFs from Multi-view Images </p>
  <p class="pub_author"> Zhiyi Li, Lihe Ding, <b>Tianfan Xue</b><br>
  arXiv 2311.15291, 2023.
[<a href="https://arxiv.org/pdf/2311.15291.pdf">PDF</a>] [<a href="https://objnerf.github.io/">Webpage</a>]</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/alignerf.webp" alt=""/>&nbsp;</td>
<td><p class="pub_title"> AligNeRF: High-Fidelity Neural Radiance Fields via Alignment-Aware Training </p>
  <p class="pub_author"> Yifan Jiang, Peter Hedman, Ben Mildenhall, Dejia Xu, Jonathan T. Barron, Zhangyang Wang, <b>Tianfan Xue</b> <br>
  Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023.
[<a href="https://arxiv.org/pdf/2211.09682.pdf">PDF</a>] [<a href="https://yifanjiang.net/alignerf">Webpage</a>]</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/MalleConv.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Fast and High-Quality Image Denoising via Malleable Convolutions</p>
  <p class="pub_author"> Yifan Jiang, Bartlomiej Wronski, Ben Mildenhall, Jonathan T. Barron, Zhangyang Wang, <b>Tianfan Xue</b> <br>
  European Conference on Computer Vision (<b>ECCV</b>), 2022.
[<a href="https://arxiv.org/pdf/2201.00392.pdf">PDF</a>] [<a href="https://yifanjiang.net/MalleConv.html">Webpage</a>]</p></td>
</tr>
	
<tr>
<td><img class="proj_thumb" src="./image/flare-2021.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> How to Train Neural Networks for Flare Removal </p>
  <p class="pub_author"> Yicheng Wu, Qiurui He, <b>Tianfan Xue</b>, Rahul Garg, Jiawen Chen, Ashok Veeraraghavan, Jonathan T. Barron <br>
  International Conference on Computer Vision <b>ICCV</b>, 2021.
[<a href="https://arxiv.org/pdf/2011.12485.pdf">PDF</a>] [<a href="https://yichengwu.github.io/flare-removal/">Webpage</a>]</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/iccv2021_dp_defocus_output.gif" alt="" height=100px/>&nbsp;</td>
<td><p class="pub_title"> Defocus Map Estimation and Deblurring from a Single Dual-Pixel Image </p>
  <p class="pub_author"> Shumian Xin, Neal Wadhwa, <b>Tianfan Xue</b>, Jonathan T. Barron, Pratul P. Srinivasan, Jiawen Chen, Ioannis Gkioulekas, Rahul Garg<br>
  International Conference on Computer Vision <b>ICCV</b>, 2021.
[<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Xin_Defocus_Map_Estimation_and_Deblurring_From_a_Single_Dual-Pixel_Image_ICCV_2021_paper.pdf">PDF</a>] [<a href="https://github.com/google-research/google-research/tree/master/dual_pixels">Code</a>]</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/dualref-2020.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Learned Dual-View Reflection Removal</p>
<p class="pub_author"> Simon Niklaus, Xuaner Cecilia Zhang, Jonathan T. Barron, Neal Wadhwa, Rahul Garg, Feng Liu, <b>Tianfan Xue</b> <br>
IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2021.
[<a href="https://arxiv.org/pdf/2010.00702.pdf">PDF</a>] [<a href="https://sniklaus.com/dualref">Webpage</a>]</p></td>
</tr>


<tr>
<td><img class="proj_thumb" src="./image/bilateral-style-transfer-2020.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Joint Bilateral Learning for Real-time Universal Photorealistic Style Transfer</p>
<p class="pub_author"> Xide Xia, Meng Zhang, <b>Tianfan Xue</b>, Zheng Sun, Hui Fang, Brian Kulis, Jiawen Chen <br>
European Conference on Computer Vision (<b>ECCV</b>), 2020. [<a href="https://arxiv.org/abs/2004.10955">arxiv-preprint</a>] [<a href="https://youtu.be/ljrpRrRlYs8">YouTube</a>] [<a href="https://drive.google.com/drive/folders/1XHtCyLZengS0ou9W5wBLDcRtvp8vSbzA">Dataset</a>] </p>
<p class="pub_title"> Real-time Localized Photorealistic Video Style Transfer. </p>
<p class="pub_author"> Xide Xia, <b>Tianfan Xue</b>, Wei-sheng Lai, Zheng Sun, Abby Chang, Brian Kulis, Jiawen Chen, 2020. <br>
IEEE/CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2021. [<a href="https://people.csail.mit.edu/tfxue/papers/wacv2021_video_style_transfer.pdf">PDF</a>] </p></td> </br>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/night-sight-sigasia-2019.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Handheld Mobile Photography in Very Low Light </p>
<p class="pub_author"> Orly Liba, Kiran Murthy, Yun-Ta Tsai, Timothy Brooks, <b>Tianfan Xue</b>, Nikhil Karnad, Qiurui He, Jonathan T. Barron, Dillon Sharlet, Ryan Geiss, Samuel W. Hasinoff, Yael Pritch, Marc Levoy <br>
ACM SIGGRAPH Asia, 2019, <b>Oral</b> <br>
[<a href="https://arxiv.org/pdf/1910.11336.pdf">PDF</a>] [<a href="https://google.github.io/night-sight/">Webpage</a>]</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/ivc2019multiviewstereo.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Multi-frame stereo matching with edges, planes, and superpixels, </p>
<p class="pub_author"> <b>Tianfan Xue</b>, Andrew Owens, Daniel Scharstein, Michael Goesele, Richard Szeliski <br>
Image and Vision Computing (<b>IVC</b>), 2019 <br>
[<a href="https://people.csail.mit.edu/tfxue/papers/ivc2019_multiviewstereo.pdf">PDF</a>] [<a href="https://people.csail.mit.edu/tfxue/project/multiview-stereo">Webpage</a>]</p></td>
</tr>


<tr>
<td><img class="proj_thumb" src="./image/cvpr2019_unprocess.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Unprocessing Images for Learned Raw Denoising, </p>
<p class="pub_author"> Tim Brooks, Ben Mildenhall, <b>Tianfan Xue</b>, Jiawen Chen, Dillon Sharlet, Jonathan T. Barron <br>
Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019 <br>
[<a href="https://people.csail.mit.edu/tfxue/papers/cvpr2019_unprocess.pdf">PDF</a>] [<a href="http://timothybrooks.com/tech/unprocessing/">Website</a>] [<a href="https://github.com/google-research/google-research/tree/master/unprocessing">github</a>] </p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/iccp2019_dark_flash.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Stereoscopic Dark Flash for Low-light Photography, </p>
<p class="pub_author"> Jian Wang, <b>Tianfan Xue</b>, Jonathan T. Barron, Jiawen Chen <br>
International Conference on Computational Photography (<b>ICCP</b>), 2019 <br>
[<a href="https://arxiv.org/pdf/1901.01370.pdf">PDF</a>] [<a href="https://youtu.be/1LZJWLagSVU">YouTube</a>] </p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/uist2018_mosculp.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"> MoSculp: Interactive Visualization of Shape and Time, </p>
<p class="pub_author"> Xiuming Zhang, Tali Dekel, <b>Tianfan Xue</b>, Andrew Owens, Qiurui He, Jiajun Wu, Stefanie Mueller, William T. Freeman <br>
User Interface Software and Technology (<b>UIST</b>), 2018 <br>
[<a href="https://people.csail.mit.edu/tfxue/papers/uist2018_mosculp.pdf">PDF</a>] [<a href="http://mosculp.csail.mit.edu/">Website</a>] [<a href="https://github.com/xiumingzhang/mosculp-demo-ui">github</a>]<br>
Press Coverage: <a href="https://www.forbes.com/sites/jenniferhicks/2018/09/25/these-researchers-turned-2d-videos-into-3d-motion-sculptures">Forbes</a>, <a href="https://www.bbc.com/news/av/technology-45552015/creating-3d-sculptures-from-2d-video-and-other-news">BBC</a>, <a href="http://mosculp.csail.mit.edu/assets/homepage.png">MIT (featured as the 9/19 homepage)</a>, <a href="http://people.csail.mit.edu/xiuming/#four">etc.</a></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/toflow.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Video Enhancement with Task-Oriented Flow, </p>
<p class="pub_author"> <b>Tianfan Xue</b>, Baian Chen, Jiajun Wu, Donglai Wei, William T. Freeman <br>
International Journal of Computer Vision (<b>IJCV</b>), 2018 <br>
[<a href="https://people.csail.mit.edu/tfxue/papers/ijcv2018_task_oriented_flow.pdf">PDF</a>] [<a href="https://arxiv.org/pdf/1711.09078.pdf">arxiv-preprint</a>] [<a href="http://toflow.csail.mit.edu/">Website</a>] [<a href="https://github.com/anchen1011/toflow">github</a>] [<a href="https://github.com/anchen1011/toflow#vimeo-90k-dataset">Dataset</a>] </p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/cvpr2018_pix3d.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Pix3D: Dataset and Methods for Single-Image 3D Shape Modeling </p>
<p class="pub_author">Xingyuan Sun*, Jiajun Wu*, Xiuming Zhang, Zhoutong Zhang, Chengkai Zhang, <b>Tianfan Xue</b>, Joshua B. Tenenbaum, and William T. Freeman<br>
Computer Vision and Pattern Recognition (<b>CVPR</b>), 2018 <br>
[<a href="https://people.csail.mit.edu/tfxue/papers/cvpr2018_pix3d.pdf">PDF</a>] [<a href="http://pix3d.csail.mit.edu/">Website</a>] [<a href="http://pix3d.csail.mit.edu/data/pix3d.zip">Dataset</a>] [<a href="https://github.com/xingyuansun/pix3d">Github</a>]</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/BBS_teaser.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Best-Buddies Similarity - Robust Template Matching using Mutual Nearest Neighbors, </p>
<p class="pub_author"> Shaul Oron, Tali Dekel, <b>Tianfan Xue</b>, William T. Freeman, Shai Avidan, <br>
IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>T-PAMI</b>), 2018 <br>
[<a href="https://people.csail.mit.edu/tfxue/papers/pami2018_best_buddy.pdf">PDF</a>] [<a href="https://arxiv.org/pdf/1609.01571.pdf">arxiv-preprint</a>] </p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/marrnet.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> MarrNet: 3D Shape Reconstruction via 2.5D Sketches </p>
<p class="pub_author"> Jiajun Wu*, Yifan Wang*, <b>Tianfan Xue</b>, Xingyuan Sun, William T. Freeman, and Joshua B. Tenenbaum <br>
Neural Information Processing Systems (<b>NIPS</b>), 2017 <br>
[<a href="https://jiajunwu.com/papers/marrnet_nips.pdf">PDF</a>] [<a href="http://marrnet.csail.mit.edu/">Website</a>]</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/visualdynamics.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"> Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks</p>
<p class="pub_author"> <b>Tianfan Xue</b>*, Jiajun Wu*, Katherine L. Bouman, and William T. Freeman, <br>
Neural Information Processing Systems (<b>NIPS</b>) 2016, <b>Oral</b>. <br>
<p class="pub_title"> Visual dynamics: Stochastic future generation via layered cross convolutional networks</p>
<p class="pub_author"> <b>Tianfan Xue</b>*, Jiajun Wu*, Katherine L. Bouman, and William T. Freeman, <br>
IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>T-PAMI</b>) 2018. <br>
[<a href="http://visualdynamics.csail.mit.edu/visualDynamics16.pdf">PDF (conference)</a>] 
[<a href="http://visualdynamics.csail.mit.edu/visualDynamics18.pdf">PDF (journal)</a>] 
[<a href="https://arxiv.org/abs/1607.02586">arxiv-preprint</a>]
[<a href="http://visualdynamics.csail.mit.edu/">Website</a>] [<a href="http://visualdynamics.csail.mit.edu/visualDynamics.mov">Video</a>]
[<a href="https://youtu.be/zidaYS85mCY">YouTube</a>] [<a href="https://github.com/tfxue/visual-dynamics">Code(Github)</a>]</p>
</td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/van.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling</p>
<p class="pub_author"> Jiajun Wu*, Chengkai Zhang*, <b>Tianfan Xue</b>, William T. Freeman, and Joshua B. Tenenbaum, <br>
Neural Information Processing Systems (<b>NIPS</b>) 2016. <br>
[<a href="https://people.csail.mit.edu/tfxue/papers/nips2016_shape.pdf">PDF</a>] [<a href="http://arxiv.org/abs/1610.07584">arxiv-preprint</a>] [<a href = "http://3dgan.csail.mit.edu/">Website</a>] [<a href="https://youtu.be/mfx7uAkUtCI">YouTube</a>] [<a href="https://github.com/zck119/3dgan-release">Code(Github)</a>]
</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/3DINN.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Single Image 3D Interpreter Network</p>
<p class="pub_author"> Jiajun Wu*, <b>Tianfan Xue</b>*, Joseph J. Lim, Yuandong Tian, Joshua B. Tenenbaum, Antonio Torralba, and William T. Freeman, <br>
European Conference on Computer Vision (<b>ECCV</b>), 2016, <b>Oral</b>. <br>
[<a href="http://3dinterpreter.csail.mit.edu/papers/3dinn_eccv.pdf">PDF</a>] [<a href = "http://3dinterpreter.csail.mit.edu/">Website</a>] [<a href = "http://3dinterpreter.csail.mit.edu/data/ikea_3DINN.zip">IKEA-dataset</a>] [<a href = "http://3dinterpreter.csail.mit.edu/data/keypoint-5.zip">Keypoint5-dataset</a>] [<a href="http://arxiv.org/abs/1604.08685">arxiv-preprint</a>] [<a href="https://github.com/jiajunwu/3dinn/">Code(Github)</a>] </p>

<p class="pub_title"> 3D Interpreter Networks for Viewer-Centered Wireframe Modeling</p>
International Journal of Computer Vision (<b>IJCV</b>), 2018. [<a href="https://arxiv.org/abs/1804.00782">arxiv-preprint</a>] </p></td>

</tr>

<tr>
<td><img class="proj_thumb" src="./image/ObstructionFreePhotography_SIGGRAPH2015.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"> A Computational Approach for Obstruction-Free Photography</p>
<p class="pub_author"> <b>Tianfan Xue</b>, Michael Rubinstein, Ce Liu, William T. Freeman, <br>
ACM SIGGRAPH 2015, <b>Oral</b>. <br>
[<a href="https://people.csail.mit.edu/mrub/papers/ObstructionFreePhotography_SIGGRAPH2015.pdf">PDF</a>] [<a href="https://www.youtube.com/watch?v=xoyNiatRIh4">Youtube</a>] [<a href="https://sites.google.com/site/obstructionfreephotography/">Website</a>]  </p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/xue2015aperture.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"> The Aperture Problem for Refractive Motion</p>
<p class="pub_author"> <b>Tianfan Xue</b>, Hossein Mobahi, Fredo Durand, William T. Freeman, <br>
IEEE Computer Society Conference on Computer Vision and Patter Recognition (CVPR) 2015. <br>
[<a href="https://people.csail.mit.edu/tfxue/RefractiveAperture/xue2015aperture.pdf">PDF</a>] [<a href="https://people.csail.mit.edu/tfxue/RefractiveAperture/index.htmlRefractiveAperture/xue2015aperture_poster.pdf">Poster</a>] [<a href="https://people.csail.mit.edu/tfxue/RefractiveAperture/lensExp.mov">Video</a>] [<a href="https://people.csail.mit.edu/tfxue/RefractiveAperture/index.html">Website</a>] </p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/xue2014fluidflow.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Refraction Wiggles for Measuring Fluid Depth and Velocity from Video </p>
<p class="pub_author"> <b>Tianfan Xue</b>, Michael Rubinstein, Neal Wadhwa, Anet Levin, Fredo Durand, William T. Freeman, <br>
European Conference on Computer Vision (ECCV) 2014, <b>Oral</b>. <br>
[<a href="https://people.csail.mit.edu/tfxue/proj/fluidflow/xue2014fluidflow.pdf">PDF</a>] [<a href="https://people.csail.mit.edu/tfxue/proj/fluidflow/download/eccvPresentFull.zip">Slides</a>] [<a href="https://people.csail.mit.edu/tfxue/proj/fluidflow/download/data.zip">Data</a>] [<a href="https://people.csail.mit.edu/tfxue/proj/fluidflow/index.html">Website</a>] [<a href="http://videolectures.net/eccv2014_xue_fluid_depth/">Presentation</a>] [<a href="https://people.csail.mit.edu/tfxue/proj/fluidflow/download/code.zip">Code</a>] </p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/cvpr2012.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Example-Based 3D Object Reconstruction from Line Drawings <p>
<p class="pub_author"> <b>Tianfan Xue</b>, Jianzhuang Liu, Xiaoou Tang, <br>
IEEE Computer Society Conference on Computer Vision and Patter Recognition (<b>CVPR</b>) 2012. <br>
[<a href="https://people.csail.mit.edu/tfxue/papers/cvpr2012_example_based.pdf">PDF</a>] [<a href="https://people.csail.mit.edu/tfxue/papers/cvpr2012_example_based_poster.pdf">Poster</a>] [<a href="https://people.csail.mit.edu/tfxue/project/linedrawing/linedrawing_dataset.zip">Dataset</a>] </p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/cvpr2011_mid.jpg" alt=""/>&nbsp;</td>
<td>
<p class="pub_title"><strong>Symmetric Piecewise Planar Object Reconstruction from a Single Image</strong></p>
<p class="pub_author"><b>Tianfan Xue</b>, Jianzhuang Liu, Xiaoou Tang, (<b>CVPR</b>) 2011.[<a href="https://people.csail.mit.edu/tfxue/papers/cvpr2011_symmetry.pdf">PDF</a>] </p>
<p class="pub_title"><strong>3D Modeling from a Single View of a Symmetric Object</strong></p>
<p class="pub_author"><b>Tianfan Xue</b>, Jianzhuang Liu, Xiaoou Tang, Transactions on Image Processing (<b>TIP</b>) 2012. [<a href="https://people.csail.mit.edu/tfxue/papers/tip2012_symmetry.pdf">PDF</a>]</p>
</td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/cvpr2010_small.jpg" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Object Cut: Complex 3D object reconstruction through line drawing separation </p>
<p class="pub_author"> <b>Tianfan Xue</b>, Jianzhuang Liu, Xiaoou Tang, <br>
Computer Society Conference on Computer Vision and Patter Recognition (<b>CVPR</b>) 2010.
[<a href="https://people.csail.mit.edu/tfxue/papers/cvpr2010_object_cut.pdf">PDF</a>]
</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/icme2012_depth_superresolution.png" alt=""/>&nbsp;</td>
<td><p class="pub_title">Joint Example-based DepthMap Super-Resolution</p>
<p class="pub_author"> Yanjie Li, <b>Tianfan Xue</b>, Lifeng Sun, Jianzhuang Liu, <br>
International Conference on Multimedia Expo (<b>ICME</b>) 2012. [<a href="https://people.csail.mit.edu/tfxue/papers/icme2012_depth_superresolution.pdf">PDF</a>] [<a href="https://people.csail.mit.edu/tfxue/papers/jointSR.zip">Code</a>]
</p></td>
</tr>

<tr>
<td><img class="proj_thumb" src="./image/mm2011_upsample.png" alt=""/>&nbsp;</td>
<td><p class="pub_title"> Fast Frame-rate Up-conversion of Depth Video via Video Coding</p>
<p class="pub_author"> Yanjie Li, Lifeng Sun, <b>Tianfan Xue</b>, <br>
ACM Multimedia (<b>MM</b>) 2011. [<a href="https://people.csail.mit.edu/tfxue/papers/mm2011_upsample.pdf">PDF</a>] 
</p></td>
</tr>

<tr><td></td><td>
    <div align="right">* indicates equal contribution</div>
</td></tr>
</table>



<!-- MISC -->
<a id="misc" class="anchor"></a>
<h2>MISC</h2></a>
<ul>
<li><p>Previous Labmates in MIT CSAIL:
<a href="http://people.csail.mit.edu/klbouman/">Katie Bouman</a>, <a href="http://people.csail.mit.edu/hmobahi/">Hossein Mobahi</a>, <a href="http://people.csail.mit.edu/mrub/">Michael Rubinstein</a>, <a href="people.csail.mit.edu/talidekel/">Tali Dekel</a>, <a href="http://people.csail.mit.edu/donglai/">Donglai Wei</a>, <a href="http://jiajunwu.com/">Jiajun Wu</a>, <a href="http://web.mit.edu/xiuming/www/">Xiuming Zhang</a>, <a href="https://ztzhang.info/">Zhoutong Zhang</a>  </p>
</li>
</ul>



<!-- hitwebcounter Code START -->
<a href="http://www.hitwebcounter.com" target="_blank">
<img src="http://hitwebcounter.com/counter/counter.php?page=6171973&style=0006&nbdigits=5&type=page&initCount=3000" title="" Alt=""   border="0" >
</a>                                        
<br/>
<!-- hitwebcounter.com --><a href="http://www.hitwebcounter.com" title="Live Stats For Website" 
target="_blank" style="font-family: Geneva, Arial, Helvetica, sans-serif; 
font-size: 10px; color: #908C86; text-decoration: underline ;">
</a>  



<div id="footer">
<div id="footer-text">
Last update: Nov. 2022. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>

</div>
</div>

<script>
function main() {
    overlay_video();
    pub_tabs();
    show_pub_by_classname('selected');
}
function overlay_video() {
    var nodes = document.querySelectorAll('.over-video');
    for(var i = 0; i < nodes.length; i++) {
	node = nodes[i]
	node.addEventListener('mouseenter', function(event) {
	    this.querySelector('.overlay-video').style.opacity = 1;
	    this.querySelector('video').currentTime = 0;
	    this.querySelector('video').play();
	});
	node.addEventListener('mouseleave', function(event) {
	    this.querySelector('.overlay-video').style.opacity = 0;
	    this.querySelector('video').pause();
	});
    }
}
function show_pub_by_classname(clsname) {
    // classnames: pub, selected, preprints
    const pub_entries = document.getElementsByClassName('pub');
    for (var i = 0; i < pub_entries.length; i++) {
	pub_el = pub_entries[i]
	if (pub_el.classList.contains(clsname)) {
	    pub_el.style.display = 'flex';
	} else {
	    pub_el.style.display = 'none';
	}
    }
}
function pub_tabs() {
    const triggerTabList = document.querySelectorAll('#pubtabs a');
    triggerTabList.forEach(triggerEl => {
	triggerEl.addEventListener('click', event => {
	    event.preventDefault();
	    show_pub_by_classname(triggerEl.dataset.bsTarget);
	});
    });
}
document.addEventListener('DOMContentLoaded', function() { main(); }, true);
</script>

</body>
</html>
